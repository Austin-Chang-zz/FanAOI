{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1 : Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teyin\\miniconda3\\envs\\ForML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import gradio as gr\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2 : Read Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists and label dictionary\n",
    "images, labels = [], []\n",
    "label_map = {\"60\": 0, \"100\": 1}\n",
    "\n",
    "def load_images_from_folder(base_path, img_size=(80, 80)):   # Uniform Input Size\n",
    "    for folder in glob.glob(os.path.join(base_path, '*')):\n",
    "        print(f\"{folder} 圖片讀取中…\")\n",
    "        label = os.path.basename(folder)\n",
    "        # print(label)\n",
    "        \n",
    "        # Skip folders that aren't in label_map\n",
    "        if label not in label_map:\n",
    "            print(f\"未定義的標籤: {label}，跳過\")\n",
    "            continue\n",
    "        \n",
    "        for file in os.listdir(folder):\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(folder, file)\n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        img = cv2.resize(img, img_size) \n",
    "                        images.append(img)   # RGB data for each images\n",
    "                        labels.append(label_map[label])   # 1 for 100 and 0 for 60\n",
    "                    else:\n",
    "                        print(f\"無法讀取圖片: {img_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"讀取檔案時出錯: {img_path}, 錯誤: {e}\")\n",
    "            else:\n",
    "                print(f\"跳過非圖片檔案: {file}\")\n",
    "\n",
    "# Define the base path and load images\n",
    "base_path = \"C:/Photos\"  # 修改此路徑\n",
    "load_images_from_folder(base_path)\n",
    "\n",
    "print(images)\n",
    "print(labels)\n",
    "\n",
    "print(f'圖片數量：{len(images)}')\n",
    "print(f'標籤數量：{len(labels)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3 : Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step -3.1 : 20% for testing and 80% for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature,test_feature,train_label,test_label = \\\n",
    "train_test_split(images,labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step -3.2 : 20% for testing and 80% for training features\n",
    "##### Conver lists into NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature=np.array(train_feature)\n",
    "test_feature=np.array(test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step -3.3 : 20% for testing and 80% for training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=np.array(train_label)\n",
    "test_label=np.array(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-3.4 : Normalizing Image Data, Dividing by 255 scales the values to a range of [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train_feature/255\n",
    "test_feature = test_feature/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-3.5 : Converting Labels to Categorical Format (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np_utils.to_categorical(train_label)\n",
    "test_label = np_utils.to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=(5,5), padding='same',input_shape=(80, 80, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5),padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=2,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=train_feature, y=train_label, validation_split=0.2,epochs=20, batch_size=200, verbose=2)\n",
    "\n",
    "scores = model.evaluate(test_feature, test_label)\n",
    "\n",
    "print('\\n準確率=',scores[1])\n",
    "model.save('fan_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_labels_predictions(images, labels,predictions,start_id, num=10):\n",
    "    plt.figure(figsize=(12, 14))\n",
    "    if num>25: num=25\n",
    "    for i in range(0, num):\n",
    "        ax=plt.subplot(5,5, 1+i)\n",
    "        ax.imshow(images[start_id])\n",
    "        if( len(predictions) > 0 ) :\n",
    "            title = 'ai = ' + str(predictions[start_id])\n",
    "            title += (' (o)' if predictions[start_id]== \\\n",
    "            labels[start_id] else ' (x)')\n",
    "            title += '\\nlabel = ' + str(labels[start_id])\n",
    "        else :\n",
    "            title = 'label = ' + str(labels[start_id])\n",
    "        ax.set_title(title,fontsize=12)\n",
    "        ax.set_xticks([]);ax.set_yticks([])\n",
    "        start_id+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Photos\\\\100', 'C:/Photos\\\\60']\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m      8\u001b[0m     img\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(file)\n\u001b[1;32m----> 9\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, dsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m80\u001b[39m))\n\u001b[0;32m     11\u001b[0m     test_feature\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"C:/Photos/*\" )  #修改照片路徑\n",
    "print(files)\n",
    "test_feature=[]\n",
    "test_label=[]\n",
    "dict_labels = {\"60\":0, \"100\":1}\n",
    "\n",
    "for file in files:\n",
    "    img=cv2.imread(file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, dsize=(80,80))\n",
    "    test_feature.append(img)\n",
    "    label=file[10:13]\n",
    "    test_label.append(dict_labels[label])\n",
    "    test_feature = np.array(test_feature).reshape(len(test_feature),80,80,3).astype('float32')\n",
    "    test_label = np.array(test_label)\n",
    "\n",
    "    test_feature_n = test_feature\n",
    "\n",
    "try:\n",
    "\n",
    "    model = load_model('/content/fan_model.h5')\n",
    "    prediction = model.predict(test_feature_n)\n",
    "    prediction = np.argmax(prediction,axis=1)\n",
    "    show_images_labels_predictions(test_feature,test_label,prediction,0,len(test_feature))\n",
    "except:\n",
    "    print(\"模型未建立!\")\n",
    "\n",
    "\n",
    "\n",
    "model = load_model(\"C:/Photos/fan_model.h5\")  #修改fan_model.h5路徑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://dbfe0acd6e5e08a63d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dbfe0acd6e5e08a63d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    }
   ],
   "source": [
    "def fan60100(image):\n",
    "    image = np.array(image.resize((80, 80))).astype(\"float32\") / 255.0\n",
    "    image = image.reshape(1, 80, 80, 3)\n",
    "    prediction = model.predict(image).tolist()[0]\n",
    "    class_names = [\"60\", \"100\"]\n",
    "    return {class_names[i]: prediction[i] for i in range(2)}\n",
    "\n",
    "inp = gr.Image(type=\"pil\")\n",
    "out = gr.Label(num_top_classes=2, label='預測結果')\n",
    "grobj = gr.Interface(fn=fan60100, inputs=inp,outputs=out, title=\"圖片辨識\")\n",
    "\n",
    "grobj.launch(share=True)\n",
    "\n",
    "\n",
    "# 模組跑完後終端機會提供一組本地應用的地址\n",
    "# 例:* Running on local URL:  http://127.0.0.1:7860\n",
    "# 將地址貼至瀏覽器即可打開"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ForML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
